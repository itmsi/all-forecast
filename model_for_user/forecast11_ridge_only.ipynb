{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47ff018c",
   "metadata": {},
   "source": [
    "# Forecast (Simplified): Ridge_log + rounded(thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4a67798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) CONFIG (keep minimal)\n",
    "# =======================\n",
    "DATA_PATH = 'alldemand_augjul_new.csv'   # adjust if needed\n",
    "FORECAST_HORIZON = 7\n",
    "FORECAST_START_DATE = None           # e.g., '2025-08-01'; None = H+1 after last history\n",
    "FORECAST_START_OFFSET_DAYS = 1\n",
    "\n",
    "FORECAST_SITE_CODES = ['KENDARI'] # e.g., ['SOFIFI', 'ANGSANA', 'ANGSANA']; None for all\n",
    "TRAIN_SITE_CODES    = None           # optional training subset filter\n",
    "\n",
    "ZERO_THR = 0.5                       # predictions < ZERO_THR => 0\n",
    "DAYFIRST = True                      # ID-style dates (dd/mm/yyyy)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e09ebd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) IMPORTS + HELPERS\n",
    "# =======================\n",
    "import os, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# TransformedTargetRegressor (fallback utk sklearn lama)\n",
    "try:\n",
    "    from sklearn.compose import TransformedTargetRegressor as TTR\n",
    "except Exception:\n",
    "    class TTR:\n",
    "        def __init__(self, regressor, func=None, inverse_func=None):\n",
    "            self.regressor = regressor\n",
    "            self.func = func if func else (lambda x: x)\n",
    "            self.inverse_func = inverse_func if inverse_func else (lambda x: x)\n",
    "        def fit(self, X, y):\n",
    "            self.regressor.fit(X, self.func(np.asarray(y))); return self\n",
    "        def predict(self, X):\n",
    "            return self.inverse_func(self.regressor.predict(X))\n",
    "\n",
    "def _rmse(y, yhat): return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    diff = np.abs(y_true - y_pred) / np.where(denom==0, 1.0, denom)\n",
    "    return np.mean(diff)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    denom = np.where(np.abs(y_true) < 1e-9, 1.0, np.abs(y_true))\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    denom = np.sum(np.abs(y_true))\n",
    "    return np.sum(np.abs(y_true - y_pred)) / (denom if denom != 0 else 1.0)\n",
    "\n",
    "def metrics(y, yhat):\n",
    "    \"\"\"Return exactly MAE, RMSE, sMAPE%, MAPE%.\"\"\"\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y, yhat),\n",
    "        \"RMSE\": _rmse(y, yhat),\n",
    "        \"sMAPE%\": smape(y, yhat) * 100.0,  # smape 0–2  -> % (0–200)\n",
    "        \"MAPE%\":  mape(y, yhat)  * 100.0,  # mape  0–∞  -> %\n",
    "    }\n",
    "\n",
    "def eval_with_rounding(y_true, y_pred, thr=0.5):\n",
    "    \"\"\"Half-up rounding + threshold, same metric keys.\"\"\"\n",
    "    x = np.asarray(y_pred, float)\n",
    "    x = np.where(x < thr, 0, x)       # threshold -> 0\n",
    "    x = np.floor(x + 0.5)             # half-up rounding\n",
    "    return {\n",
    "        \"MAE\": mean_absolute_error(y_true, x),\n",
    "        \"RMSE\": _rmse(y_true, x),\n",
    "        \"sMAPE%\": smape(y_true, x) * 100.0,\n",
    "        \"MAPE%\":  mape(y_true, x)  * 100.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def safe_save_csv(df, path):\n",
    "    p = Path(path); p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = p.with_suffix(p.suffix + '.tmp')\n",
    "    df.to_csv(tmp, index=False, encoding='utf-8-sig'); os.replace(tmp, p)\n",
    "    print(f\"Saved: {p}\")\n",
    "\n",
    "def make_ohe(dense=False):\n",
    "    try:    return OneHotEncoder(handle_unknown='ignore', sparse_output=not dense)\n",
    "    except TypeError: return OneHotEncoder(handle_unknown='ignore', sparse=not dense)\n",
    "\n",
    "def complete_calendar_daily(df, group_cols=('partnumber','site_code'), target='demand_qty'):\n",
    "    out = []\n",
    "    for keys, g in df.groupby(list(group_cols), sort=False):\n",
    "        gd = (g.groupby('date', as_index=False)[target].sum().sort_values('date'))\n",
    "        idx = pd.date_range(gd['date'].min(), gd['date'].max(), freq='D')\n",
    "        gd = gd.set_index('date').reindex(idx).fillna(0.0).rename_axis('date').reset_index()\n",
    "        for col, val in zip(group_cols, (keys if isinstance(keys, tuple) else (keys,))):\n",
    "            gd[col] = val\n",
    "        out.append(gd[[*group_cols, 'date', target]])\n",
    "    return pd.concat(out, ignore_index=True) if out else df\n",
    "\n",
    "def add_calendar_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
    "    return df\n",
    "\n",
    "def add_group_lags_rolls(df, group_cols, target_col='demand_qty',\n",
    "                         lags=(1,7,14,28), roll_windows=(7,14,28)):\n",
    "    df = df.sort_values(group_cols + ['date']).reset_index(drop=True)\n",
    "    g = df.groupby(group_cols, group_keys=False)\n",
    "    for L in lags: df[f'lag_{L}'] = g[target_col].shift(L)\n",
    "    for W in roll_windows: df[f'rollmean_{W}'] = g[target_col].shift(1).rolling(W).mean()\n",
    "    return df\n",
    "\n",
    "def robust_read_table(path):\n",
    "    if path.lower().endswith(('.xlsx','.xls')):\n",
    "        return pd.read_excel(path, dtype=str)\n",
    "    for enc in ('utf-8-sig','cp1252','latin1','iso-8859-1'):\n",
    "        try:\n",
    "            df_ = pd.read_csv(path, sep=None, engine='python', dtype=str, encoding=enc)\n",
    "            print(f\"Loaded with encoding={enc}\"); return df_\n",
    "        except Exception: continue\n",
    "    return pd.read_csv(path, sep=None, engine='python', dtype=str, encoding='latin1', errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a522b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded with encoding=utf-8-sig\n",
      "      partnumber site_code       date  demand_qty\n",
      "0                  KENDARI 2024-10-29        20.0\n",
      "1   '19000396262    SOFIFI 2024-10-28         2.0\n",
      "2  '612600013467   KENDARI 2024-12-23         1.0\n",
      "3   015114855TF3    SOFIFI 2024-11-27        20.0\n",
      "4   0533-4820062    SOFIFI 2024-11-09         1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) LOAD & NORMALIZE\n",
    "# =======================\n",
    "df = robust_read_table(DATA_PATH)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "req = {'demand_qty','date','partnumber','site_code'}\n",
    "miss = req - set(df.columns)\n",
    "if miss: raise ValueError(f\"Kolom wajib hilang: {miss}. Header: {list(df.columns)}\")\n",
    "\n",
    "df['partnumber'] = df['partnumber'].astype(str).str.strip()\n",
    "df['site_code']  = df['site_code'].astype(str).str.strip()\n",
    "d = pd.to_datetime(df['date'], dayfirst=DAYFIRST, errors='coerce')\n",
    "if d.isna().mean() > 0.2:\n",
    "    d = pd.to_datetime(df['date'], dayfirst=not DAYFIRST, errors='coerce')\n",
    "df['date'] = d\n",
    "if df['date'].isna().any():\n",
    "    raise ValueError(\"Ada tanggal gagal parse. Cek format kolom 'date'.\")\n",
    "\n",
    "df['demand_qty'] = pd.to_numeric(df['demand_qty'], errors='coerce').fillna(0)\n",
    "df = df.sort_values(['partnumber','site_code','date']).reset_index(drop=True)\n",
    "\n",
    "# Aggregate daily, complete calendar, clip outliers per series (p99)\n",
    "df = (df.groupby(['partnumber','site_code','date'], as_index=False)\n",
    "        .agg(demand_qty=('demand_qty','sum')))\n",
    "df = complete_calendar_daily(df, group_cols=('partnumber','site_code'), target='demand_qty')\n",
    "p99 = df.groupby(['partnumber','site_code'])['demand_qty'].transform(lambda s: s.quantile(0.99))\n",
    "df['demand_qty'] = df['demand_qty'].clip(lower=0, upper=p99)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3fb3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: Naive t-1 (raw)\n",
      "{'MAE': 1.7114195348837171, 'RMSE': np.float64(33.867473040085635), 'sMAPE%': np.float64(22.37757725980452), 'MAPE%': np.float64(52.07070098544621)}\n",
      "\n",
      "Baseline: Naive t-7 (raw)\n",
      "{'MAE': 1.6966269767441824, 'RMSE': np.float64(33.741731794102), 'sMAPE%': np.float64(22.1672356568317), 'MAPE%': np.float64(50.04961018930172)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) FEATURE ENGINEERING & SPLIT\n",
    "# =======================\n",
    "group_cols = ['partnumber','site_code']\n",
    "df_model = df if TRAIN_SITE_CODES is None else df[df['site_code'].isin(TRAIN_SITE_CODES)].copy()\n",
    "if df_model.empty: raise ValueError(\"TRAIN_SITE_CODES filter produced empty data.\")\n",
    "\n",
    "df_fe = add_calendar_features(df_model)\n",
    "df_fe = add_group_lags_rolls(df_fe, group_cols, target_col='demand_qty',\n",
    "                             lags=(1,7,14,28), roll_windows=(7,14,28))\n",
    "need = [c for c in df_fe.columns if c.startswith('lag_') or c.startswith('rollmean_')]\n",
    "df_fe = df_fe[df_fe[need].notnull().all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "feature_cols_cat = ['partnumber','site_code']\n",
    "feature_cols_num = ['year','month','day','dayofweek','weekofyear','is_month_start','is_month_end'] + need\n",
    "\n",
    "cutoff = df_fe['date'].max() - pd.Timedelta(days=max(28, 2*FORECAST_HORIZON))\n",
    "train = df_fe[df_fe['date'] <= cutoff].copy()\n",
    "valid = df_fe[df_fe['date'] >  cutoff].copy()\n",
    "X_train = pd.concat([train[feature_cols_cat], train[feature_cols_num]], axis=1)\n",
    "X_valid = pd.concat([valid[feature_cols_cat], valid[feature_cols_num]], axis=1)\n",
    "y_train = train['demand_qty'].astype(float).values\n",
    "y_valid = valid['demand_qty'].astype(float).values\n",
    "\n",
    "print(\"Baseline: Naive t-1 (raw)\")\n",
    "print(metrics(y_valid, valid.get('lag_1', 0).fillna(0).values))\n",
    "\n",
    "print(\"\\nBaseline: Naive t-7 (raw)\")\n",
    "print(metrics(y_valid, valid.get('lag_7', 0).fillna(0).values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d7310e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>eval</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE%</th>\n",
       "      <th>MAPE%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge_log</td>\n",
       "      <td>raw</td>\n",
       "      <td>1.326114</td>\n",
       "      <td>32.935690</td>\n",
       "      <td>199.320098</td>\n",
       "      <td>12.491708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge_log</td>\n",
       "      <td>rounded(thr=0.5)</td>\n",
       "      <td>1.292733</td>\n",
       "      <td>32.941622</td>\n",
       "      <td>17.673500</td>\n",
       "      <td>8.836977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model              eval       MAE       RMSE      sMAPE%      MAPE%\n",
       "0  Ridge_log               raw  1.326114  32.935690  199.320098  12.491708\n",
       "1  Ridge_log  rounded(thr=0.5)  1.292733  32.941622   17.673500   8.836977"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 4) MODEL = Ridge_log ONLY\n",
    "# =======================\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocess_sparse = ColumnTransformer(\n",
    "    transformers=[('cat', make_ohe(dense=False), feature_cols_cat)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "ridge_log = Pipeline([\n",
    "    (\"prep\", preprocess_sparse),\n",
    "    (\"reg\", TTR(\n",
    "        regressor=Ridge(alpha=1.0, random_state=RANDOM_STATE) if 'random_state' in Ridge().get_params() else Ridge(alpha=1.0),\n",
    "        func=np.log1p, inverse_func=np.expm1\n",
    "    ))\n",
    "])\n",
    "\n",
    "ridge_log.fit(X_train, y_train)\n",
    "y_pred = ridge_log.predict(X_valid)\n",
    "\n",
    "# Evaluate (raw & rounded thr=0.5)\n",
    "m_raw = metrics(y_valid, y_pred)                       # <— tanpa as_percent\n",
    "m_rnd = eval_with_rounding(y_valid, y_pred, thr=ZERO_THR)\n",
    "\n",
    "eval_df = pd.DataFrame([\n",
    "    {\"model\": \"Ridge_log\", \"eval\": \"raw\", **m_raw},\n",
    "    {\"model\": \"Ridge_log\", \"eval\": f\"rounded(thr={ZERO_THR})\", **m_rnd},\n",
    "])[[\"model\",\"eval\",\"MAE\",\"RMSE\",\"sMAPE%\",\"MAPE%\"]]     # tampilkan 4 metrik saja\n",
    "\n",
    "eval_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "370d9825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample forecast:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partnumber</th>\n",
       "      <th>site_code</th>\n",
       "      <th>date</th>\n",
       "      <th>yhat_raw</th>\n",
       "      <th>yhat_thr</th>\n",
       "      <th>yhat_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>KENDARI</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>KENDARI</td>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>KENDARI</td>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>KENDARI</td>\n",
       "      <td>2025-08-04</td>\n",
       "      <td>0.069541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>KENDARI</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>0.062186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  partnumber site_code       date  yhat_raw  yhat_thr  yhat_round\n",
       "0              KENDARI 2025-08-01  0.020320       0.0           0\n",
       "1              KENDARI 2025-08-02  0.038793       0.0           0\n",
       "2              KENDARI 2025-08-03  0.024778       0.0           0\n",
       "3              KENDARI 2025-08-04  0.069541       0.0           0\n",
       "4              KENDARI 2025-08-05  0.062186       0.0           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: forecast_ridge_log_thr05.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) FORECAST LOOP (fixed model + outputs)\n",
    "# =======================\n",
    "best_est = ridge_log  # fixed\n",
    "\n",
    "# subset sites for output\n",
    "df_sites = df if FORECAST_SITE_CODES is None else df[df['site_code'].isin(FORECAST_SITE_CODES)].copy()\n",
    "if df_sites.empty: raise ValueError(\"FORECAST_SITE_CODES tidak ditemukan di data.\")\n",
    "\n",
    "def one_day_forecast(history_df, fdate):\n",
    "    hist = add_calendar_features(history_df)\n",
    "    hist = add_group_lags_rolls(hist, group_cols, target_col='demand_qty',\n",
    "                                lags=(1,7,14,28), roll_windows=(7,14,28))\n",
    "    latest = (hist.sort_values('date')\n",
    "                .groupby(group_cols, as_index=False)\n",
    "                .tail(1)[[*group_cols] + [c for c in hist.columns\n",
    "                                          if c.startswith('lag_') or c.startswith('rollmean_')]])\n",
    "\n",
    "    combos = df_sites[group_cols].drop_duplicates().reset_index(drop=True)\n",
    "    combos['date'] = fdate\n",
    "    combos = add_calendar_features(combos).merge(latest, on=group_cols, how='left')\n",
    "\n",
    "    lagroll_cols = [c for c in [*latest.columns] if c.startswith('lag_') or c.startswith('rollmean_')]\n",
    "    for c in lagroll_cols:\n",
    "        if c in combos: combos[c] = combos[c].fillna(0)\n",
    "\n",
    "    Xf = pd.concat([combos[['partnumber','site_code']],\n",
    "                    combos[['year','month','day','dayofweek','weekofyear','is_month_start','is_month_end'] + lagroll_cols]], axis=1)\n",
    "    raw_model = np.maximum(0, best_est.predict(Xf))              # raw >= 0\n",
    "    raw_thr   = np.where(raw_model < ZERO_THR, 0, raw_model)     # threshold to zero\n",
    "    yhat      = np.floor(raw_thr + 0.5).astype(int)             # half-up rounding\n",
    "\n",
    "    out = combos[[*group_cols]].copy()\n",
    "    out['date'] = fdate\n",
    "    out['yhat_raw']   = raw_model\n",
    "    out['yhat_thr']   = raw_thr\n",
    "    out['yhat_round'] = yhat\n",
    "    return out\n",
    "\n",
    "start_date = pd.to_datetime(FORECAST_START_DATE) if FORECAST_START_DATE else (df['date'].max() + pd.Timedelta(days=FORECAST_START_OFFSET_DAYS))\n",
    "forecasts = []\n",
    "hist_all = df.copy()\n",
    "\n",
    "for h in range(FORECAST_HORIZON):\n",
    "    fdate = start_date + pd.Timedelta(days=h)\n",
    "    day_fc = one_day_forecast(hist_all, fdate)\n",
    "    forecasts.append(day_fc)\n",
    "    # append rounded predictions back as history for iterative features\n",
    "    add_back = day_fc.rename(columns={'yhat_round':'demand_qty'})[['partnumber','site_code','date','demand_qty']].copy()\n",
    "    hist_all = pd.concat([hist_all, add_back], ignore_index=True)\n",
    "\n",
    "forecast_df = (pd.concat(forecasts, ignore_index=True)\n",
    "                 .sort_values(['partnumber','site_code','date'])\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"Sample forecast:\")\n",
    "display(forecast_df.head())\n",
    "\n",
    "safe_save_csv(forecast_df, \"forecast_ridge_log_thr05.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc0a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) CONFIG\n",
    "# =======================\n",
    "DATA_PATH = 'alldemand_augjul.csv'\n",
    "\n",
    "FORECAST_HORIZON = 7\n",
    "FORECAST_START_DATE = None             # contoh '2025-08-01'; None = H+1 dari histori terakhir\n",
    "FORECAST_START_OFFSET_DAYS = 1\n",
    "\n",
    "FORECAST_SITE_CODES = ['IEL-ST-KDI']             # contoh: ['IEL-MU-SFI', 'IEL-KS-ANGSANA']\n",
    "TRAIN_SITE_CODES    = None             # batasi data training ke site tertentu (opsional)\n",
    "\n",
    "ROUNDING_MODE = 'half_up'              # 'half_up' | 'round' | 'ceil' | 'floor'\n",
    "ZERO_THR = 0.5                         # prediksi < ZERO_THR dianggap 0 (tuning 0.1–1.0)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "DAYFIRST = True                        # parsing tanggal day-first (format umum ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de99add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) IMPORTS + HELPERS\n",
    "# =======================\n",
    "import os, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# TransformedTargetRegressor (fallback utk sklearn lama)\n",
    "try:\n",
    "    from sklearn.compose import TransformedTargetRegressor as TTR\n",
    "except Exception:\n",
    "    class TTR:\n",
    "        def __init__(self, regressor, func=None, inverse_func=None):\n",
    "            self.regressor = regressor\n",
    "            self.func = func if func else (lambda x: x)\n",
    "            self.inverse_func = inverse_func if inverse_func else (lambda x: x)\n",
    "        def fit(self, X, y):\n",
    "            self.regressor.fit(X, self.func(np.asarray(y))); return self\n",
    "        def predict(self, X):\n",
    "            return self.inverse_func(self.regressor.predict(X))\n",
    "\n",
    "def _rmse(y, yhat):\n",
    "    try: return mean_squared_error(y, yhat, squared=False)\n",
    "    except TypeError: return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def smape(y, yhat):\n",
    "    y = np.asarray(y, float); yhat = np.asarray(yhat, float)\n",
    "    d = np.abs(y) + np.abs(yhat); d = np.where(d==0, 1.0, d)\n",
    "    return np.mean(2*np.abs(yhat - y)/d)   # 0–2; kalikan 100 untuk %\n",
    "\n",
    "def mape(y, yhat):\n",
    "    y = np.asarray(y, float); yhat = np.asarray(yhat, float)\n",
    "    denom = np.where(y==0, 1.0, y)\n",
    "    return np.mean(np.abs((y - yhat)/denom))  # 0–∞; kalikan 100 untuk %\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float); y_pred = np.asarray(y_pred, float)\n",
    "    den = np.sum(np.abs(y_true)); den = den if den != 0 else 1.0\n",
    "    return 100 * np.sum(np.abs(y_true - y_pred)) / den\n",
    "\n",
    "def mase(y_true, y_pred, insample):\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    denom = mean_absolute_error(insample[1:], insample[:-1]) if len(insample) > 1 else 1.0\n",
    "    return mean_absolute_error(y_true, y_pred) / (denom if denom != 0 else 1.0)\n",
    "\n",
    "def metrics(y, yhat, as_percent=False):\n",
    "    m = dict(MAE=mean_absolute_error(y, yhat),\n",
    "             RMSE=_rmse(y, yhat),\n",
    "             sMAPE=smape(y, yhat),\n",
    "             MAPE=mape(y, yhat))\n",
    "    if as_percent:\n",
    "        m['sMAPE'] *= 100.0\n",
    "        m['MAPE']  *= 100.0\n",
    "    return m\n",
    "\n",
    "def print_metrics(m):\n",
    "    for k,v in m.items(): print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "def eval_with_rounding(y_true, y_pred, thr=0.5):\n",
    "    x = np.asarray(y_pred, float)\n",
    "    x = np.where(x < thr, 0, x)                 # threshold -> nol\n",
    "    x = np.floor(x + 0.5)                       # half-up rounding\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, x),\n",
    "        'RMSE': _rmse(y_true, x),\n",
    "        'sMAPE%': smape(y_true, x) * 100,\n",
    "        'MAPE%': mape(y_true, x) * 100,\n",
    "        'WAPE%': wape(y_true, x),\n",
    "    }\n",
    "\n",
    "def safe_save_csv(df, path):\n",
    "    p = Path(path); p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        tmp = p.with_suffix(p.suffix + '.tmp')\n",
    "        df.to_csv(tmp, index=False, encoding='utf-8-sig'); os.replace(tmp, p)\n",
    "        print(f\"Saved: {p}\")\n",
    "    except PermissionError:\n",
    "        alt = p.with_name(p.stem + f'_{int(time.time())}' + p.suffix)\n",
    "        df.to_csv(alt, index=False, encoding='utf-8-sig'); print(f\"Target locked. Saved: {alt}\")\n",
    "\n",
    "def add_calendar_features(df):\n",
    "    df = df.copy()\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype(int)\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
    "    return df\n",
    "\n",
    "def add_group_lags_rolls(df, group_cols, target_col='demand_qty',\n",
    "                         lags=(1,7,14,28), roll_windows=(7,14,28)):\n",
    "    df = df.sort_values(group_cols + ['date']).reset_index(drop=True)\n",
    "    g = df.groupby(group_cols, group_keys=False)\n",
    "    for L in lags: df[f'lag_{L}'] = g[target_col].shift(L)\n",
    "    for W in roll_windows: df[f'rollmean_{W}'] = g[target_col].shift(1).rolling(W).mean()\n",
    "    return df\n",
    "\n",
    "def complete_calendar_daily(df, group_cols=('partnumber','site_code'), target='demand_qty'):\n",
    "    out = []\n",
    "    for keys, g in df.groupby(list(group_cols), sort=False):\n",
    "        gd = (g.groupby('date', as_index=False)[target].sum().sort_values('date'))\n",
    "        idx = pd.date_range(gd['date'].min(), gd['date'].max(), freq='D')\n",
    "        gg = gd.set_index('date').reindex(idx).rename_axis('date').reset_index()\n",
    "        gg[target] = pd.to_numeric(gg[target], errors='coerce').fillna(0)\n",
    "        if not isinstance(keys, tuple): keys = (keys,)\n",
    "        for c, v in zip(group_cols, keys): gg[c] = v\n",
    "        out.append(gg)\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "def round_series(x, mode='half_up'):\n",
    "    if mode == 'half_up': return np.floor(x + 0.5).astype(int)\n",
    "    if mode == 'round':   return np.round(x).astype(int)\n",
    "    if mode == 'ceil':    return np.ceil(x).astype(int)\n",
    "    if mode == 'floor':   return np.floor(x).astype(int)\n",
    "    return np.round(x).astype(int)\n",
    "\n",
    "def make_ohe(dense=False):\n",
    "    try:    return OneHotEncoder(handle_unknown='ignore', sparse_output=not dense)\n",
    "    except TypeError: return OneHotEncoder(handle_unknown='ignore', sparse=not dense)\n",
    "\n",
    "def robust_read_table(path):\n",
    "    if path.lower().endswith(('.xlsx','.xls')):\n",
    "        return pd.read_excel(path, dtype=str)\n",
    "    for enc in ('utf-8-sig','cp1252','latin1','iso-8859-1'):\n",
    "        try:\n",
    "            df_ = pd.read_csv(path, sep=None, engine='python', dtype=str, encoding=enc)\n",
    "            print(f\"Loaded with encoding={enc}\"); return df_\n",
    "        except Exception:\n",
    "            continue\n",
    "    # fallback\n",
    "    return pd.read_csv(path, sep=None, engine='python', dtype=str, encoding='latin1', errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904f48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded with encoding=utf-8-sig\n"
     ]
    }
   ],
   "source": [
    "# 2) LOAD & NORMALIZE\n",
    "# =======================\n",
    "df = robust_read_table(DATA_PATH)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "req = {'demand_qty','date','partnumber','site_code'}\n",
    "miss = req - set(df.columns)\n",
    "if miss: raise ValueError(f\"Kolom wajib hilang: {miss}. Header: {list(df.columns)}\")\n",
    "\n",
    "df['partnumber'] = df['partnumber'].astype(str).str.strip()\n",
    "df['site_code']  = df['site_code'].astype(str).str.strip()\n",
    "d = pd.to_datetime(df['date'], dayfirst=DAYFIRST, errors='coerce')\n",
    "if d.isna().mean() > 0.2:\n",
    "    d = pd.to_datetime(df['date'], dayfirst=not DAYFIRST, errors='coerce')\n",
    "df['date'] = d\n",
    "if df['date'].isna().any():\n",
    "    raise ValueError(\"Ada tanggal gagal parse. Cek format kolom 'date'.\")\n",
    "\n",
    "df['demand_qty'] = pd.to_numeric(df['demand_qty'], errors='coerce').fillna(0)\n",
    "df = df.sort_values(['partnumber','site_code','date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b961f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) AGG DAILY + CALENDAR + CLAMP\n",
    "# =======================\n",
    "df = (df.groupby(['partnumber','site_code','date'], as_index=False)\n",
    "        .agg(demand_qty=('demand_qty','sum')))\n",
    "df = complete_calendar_daily(df, group_cols=('partnumber','site_code'), target='demand_qty')\n",
    "p99 = df.groupby(['partnumber','site_code'])['demand_qty'].transform(lambda s: s.quantile(0.99))\n",
    "df['demand_qty'] = df['demand_qty'].clip(lower=0, upper=p99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee08e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 4) TRAINING SUBSET (opsional)\n",
    "# =======================\n",
    "df_model = df if TRAIN_SITE_CODES is None else df[df['site_code'].isin(TRAIN_SITE_CODES)].copy()\n",
    "if TRAIN_SITE_CODES is not None and df_model.empty:\n",
    "    raise ValueError(\"TRAIN_SITE_CODES tidak ditemukan di data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4da217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) FEATURE ENGINEERING\n",
    "# =======================\n",
    "group_cols = ['partnumber','site_code']\n",
    "df_fe = add_calendar_features(df_model)\n",
    "df_fe = add_group_lags_rolls(df_fe, group_cols, target_col='demand_qty',\n",
    "                             lags=(1,7,14,28), roll_windows=(7,14,28))\n",
    "need = [c for c in df_fe.columns if c.startswith('lag_') or c.startswith('rollmean_')]\n",
    "df_fe = df_fe[df_fe[need].notnull().all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "feature_cols_cat = ['partnumber','site_code']\n",
    "feature_cols_num = ['year','month','day','dayofweek','weekofyear','is_month_start','is_month_end'] + need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb56807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: Naive t-1 (raw)\n",
      "MAE: 1.6807\n",
      "RMSE: 34.9450\n",
      "sMAPE: 20.9861\n",
      "MAPE: 48.7361\n",
      "\n",
      "Baseline: Naive t-7 (raw)\n",
      "MAE: 1.6625\n",
      "RMSE: 34.8148\n",
      "sMAPE: 20.5459\n",
      "MAPE: 47.1213\n"
     ]
    }
   ],
   "source": [
    "# 6) SPLIT & BASELINES\n",
    "# =======================\n",
    "cutoff = df_fe['date'].max() - pd.Timedelta(days=max(28, 2*FORECAST_HORIZON))\n",
    "train = df_fe[df_fe['date'] <= cutoff].copy()\n",
    "valid = df_fe[df_fe['date'] >  cutoff].copy()\n",
    "\n",
    "X_train = pd.concat([train[feature_cols_cat], train[feature_cols_num]], axis=1)\n",
    "X_valid = pd.concat([valid[feature_cols_cat], valid[feature_cols_num]], axis=1)\n",
    "y_train = train['demand_qty'].astype(float).values\n",
    "y_valid = valid['demand_qty'].astype(float).values\n",
    "\n",
    "print(\"Baseline: Naive t-1 (raw)\")\n",
    "print_metrics(metrics(y_valid, valid.get('lag_1', 0).fillna(0).values, as_percent=True))\n",
    "print(\"\\nBaseline: Naive t-7 (raw)\")\n",
    "print_metrics(metrics(y_valid, valid.get('lag_7', 0).fillna(0).values, as_percent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663bd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) PREPROCESS + CANDIDATE MODELS\n",
    "# =======================\n",
    "preprocess_sparse = ColumnTransformer(\n",
    "    transformers=[('cat', make_ohe(dense=False), feature_cols_cat)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "preprocess_dense = ColumnTransformer(\n",
    "    transformers=[('cat', make_ohe(dense=True), feature_cols_cat)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "CANDIDATES = {\n",
    "    \"RF_log\": Pipeline([\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"reg\", TTR(\n",
    "            regressor=RandomForestRegressor(\n",
    "                n_estimators=800, max_depth=None, min_samples_leaf=2,\n",
    "                n_jobs=-1, random_state=RANDOM_STATE\n",
    "            ),\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ]),\n",
    "    \"ET_log\": Pipeline([\n",
    "        (\"prep\", preprocess_sparse),\n",
    "        (\"reg\", TTR(\n",
    "            regressor=ExtraTreesRegressor(\n",
    "                n_estimators=800, max_depth=None, min_samples_leaf=2,\n",
    "                n_jobs=-1, random_state=RANDOM_STATE\n",
    "            ),\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ]),\n",
    "    \"GBR_log\": Pipeline([\n",
    "        (\"prep\", preprocess_dense),\n",
    "        (\"reg\", TTR(\n",
    "            regressor=GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ]),\n",
    "    \"Ridge_log\": Pipeline([\n",
    "        (\"prep\", preprocess_dense),\n",
    "        (\"reg\", TTR(\n",
    "            regressor=Ridge(alpha=1.0),\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e21dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF_log (raw):\n",
      "MAE: 1.3337\n",
      "RMSE: 34.0131\n",
      "sMAPE: 173.2997\n",
      "MAPE: 13.3423\n",
      "WAPE% (raw): 103.3689  MASE: 2.2015\n",
      "RF_log (rounded + thr=0.5):\n",
      "MAE: 1.3082\n",
      "RMSE: 34.0154\n",
      "sMAPE%: 20.8042\n",
      "MAPE%: 10.5495\n",
      "WAPE%: 101.3923\n",
      "\n",
      "ET_log (raw):\n",
      "MAE: 1.3337\n",
      "RMSE: 34.0099\n",
      "sMAPE: 169.9400\n",
      "MAPE: 13.3074\n",
      "WAPE% (raw): 103.3700  MASE: 2.2016\n",
      "ET_log (rounded + thr=0.5):\n",
      "MAE: 1.3098\n",
      "RMSE: 34.0100\n",
      "sMAPE%: 20.2248\n",
      "MAPE%: 10.7165\n",
      "WAPE%: 101.5161\n",
      "\n",
      "GBR_log (raw):\n",
      "MAE: 1.3265\n",
      "RMSE: 34.0167\n",
      "sMAPE: 199.0608\n",
      "MAPE: 12.2918\n",
      "WAPE% (raw): 102.8113  MASE: 2.1897\n",
      "GBR_log (rounded + thr=0.5):\n",
      "MAE: 1.2950\n",
      "RMSE: 34.0206\n",
      "sMAPE%: 17.4356\n",
      "MAPE%: 8.8996\n",
      "WAPE%: 100.3713\n",
      "\n",
      "Ridge_log (raw):\n",
      "MAE: 1.3269\n",
      "RMSE: 34.0153\n",
      "sMAPE: 199.2902\n",
      "MAPE: 12.3770\n",
      "WAPE% (raw): 102.8384  MASE: 2.1902\n",
      "Ridge_log (rounded + thr=0.5):\n",
      "MAE: 1.2938\n",
      "RMSE: 34.0208\n",
      "sMAPE%: 17.5820\n",
      "MAPE%: 8.7962\n",
      "WAPE%: 100.2785\n",
      "\n",
      "== Best model by RMSE (raw): ET_log ==\n"
     ]
    }
   ],
   "source": [
    "# 8) TRAIN, EVALUATE, PICK BEST\n",
    "# =======================\n",
    "results, fitted = {}, {}\n",
    "\n",
    "for name, est in CANDIDATES.items():\n",
    "    est.fit(X_train, y_train)\n",
    "    y_pred = est.predict(X_valid)\n",
    "\n",
    "    # raw metrics\n",
    "    m_raw = metrics(y_valid, y_pred, as_percent=True)\n",
    "    print(f\"\\n{name} (raw):\"); print_metrics(m_raw)\n",
    "    print(f\"WAPE% (raw): {wape(y_valid, y_pred):.4f}  MASE: {mase(y_valid, y_pred, y_train):.4f}\")\n",
    "\n",
    "    # rounded + threshold metrics\n",
    "    m_rnd = eval_with_rounding(y_valid, y_pred, thr=ZERO_THR)\n",
    "    print(f\"{name} (rounded + thr={ZERO_THR}):\")\n",
    "    for k,v in m_rnd.items(): print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    results[name] = m_raw  # gunakan RMSE raw untuk pemilihan model\n",
    "    fitted[name]  = est\n",
    "\n",
    "best_name = min(results, key=lambda k: results[k][\"RMSE\"])\n",
    "best_est = fitted[best_name]\n",
    "print(f\"\\n== Best model by RMSE (raw): {best_name} ==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51038d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>eval</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE%</th>\n",
       "      <th>MAPE%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ET_log</td>\n",
       "      <td>raw</td>\n",
       "      <td>1.3337</td>\n",
       "      <td>34.0099</td>\n",
       "      <td>169.9400</td>\n",
       "      <td>13.3074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF_log</td>\n",
       "      <td>raw</td>\n",
       "      <td>1.3337</td>\n",
       "      <td>34.0131</td>\n",
       "      <td>173.2997</td>\n",
       "      <td>13.3423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge_log</td>\n",
       "      <td>raw</td>\n",
       "      <td>1.3269</td>\n",
       "      <td>34.0153</td>\n",
       "      <td>199.2902</td>\n",
       "      <td>12.3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GBR_log</td>\n",
       "      <td>raw</td>\n",
       "      <td>1.3265</td>\n",
       "      <td>34.0167</td>\n",
       "      <td>199.0608</td>\n",
       "      <td>12.2918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ET_log</td>\n",
       "      <td>rounded(thr=0.5)</td>\n",
       "      <td>1.3098</td>\n",
       "      <td>34.0100</td>\n",
       "      <td>20.2248</td>\n",
       "      <td>10.7165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RF_log</td>\n",
       "      <td>rounded(thr=0.5)</td>\n",
       "      <td>1.3082</td>\n",
       "      <td>34.0154</td>\n",
       "      <td>20.8042</td>\n",
       "      <td>10.5495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>GBR_log</td>\n",
       "      <td>rounded(thr=0.5)</td>\n",
       "      <td>1.2950</td>\n",
       "      <td>34.0206</td>\n",
       "      <td>17.4356</td>\n",
       "      <td>8.8996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ridge_log</td>\n",
       "      <td>rounded(thr=0.5)</td>\n",
       "      <td>1.2938</td>\n",
       "      <td>34.0208</td>\n",
       "      <td>17.5820</td>\n",
       "      <td>8.7962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Kumpulkan metrik ke DataFrame & tampilkan penuh ===\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "rows = []\n",
    "for name, est in fitted.items():        # fitted = dict model terlatih dari langkahmu\n",
    "    y_pred = est.predict(X_valid)\n",
    "\n",
    "    # raw\n",
    "    m_raw = metrics(y_valid, y_pred, as_percent=True)\n",
    "    rows.append({\n",
    "        \"model\": name, \"eval\": \"raw\",\n",
    "        \"MAE\": m_raw[\"MAE\"], \"RMSE\": m_raw[\"RMSE\"],\n",
    "        \"sMAPE%\": m_raw[\"sMAPE\"], \"MAPE%\": m_raw[\"MAPE\"],\n",
    "    })\n",
    "\n",
    "    # rounded + threshold\n",
    "    m_rnd = eval_with_rounding(y_valid, y_pred, thr=ZERO_THR)  # ZERO_THR dari config\n",
    "    rows.append({\n",
    "        \"model\": name, \"eval\": f\"rounded(thr={ZERO_THR})\",\n",
    "        **m_rnd\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df = results_df[\n",
    "    [\"model\",\"eval\",\"MAE\",\"RMSE\",\"sMAPE%\",\"MAPE%\"]\n",
    "].sort_values([\"eval\",\"RMSE\"], ascending=[True, True])\n",
    "\n",
    "# Atur tampilan agar tidak terpotong\n",
    "pd.set_option(\"display.max_rows\", 10000)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 0)           # lebar fleksibel\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.4f}\")\n",
    "\n",
    "display(HTML(results_df.to_html(index=False)))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d55384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model by MAPE% on rounded(thr=0.5): Ridge_log | MAPE%=8.7962\n",
      "\n",
      "Sample forecast:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>partnumber</th>\n",
       "      <th>site_code</th>\n",
       "      <th>forecast_qty</th>\n",
       "      <th>forecast_qty_raw</th>\n",
       "      <th>forecast_qty_raw_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>06.11251.2005</td>\n",
       "      <td>IEL-ST-KDI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-02</td>\n",
       "      <td>06.11251.2005</td>\n",
       "      <td>IEL-ST-KDI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-03</td>\n",
       "      <td>06.11251.2005</td>\n",
       "      <td>IEL-ST-KDI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-04</td>\n",
       "      <td>06.11251.2005</td>\n",
       "      <td>IEL-ST-KDI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>06.11251.2005</td>\n",
       "      <td>IEL-ST-KDI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     partnumber   site_code  forecast_qty  forecast_qty_raw  \\\n",
       "0 2025-08-01  06.11251.2005  IEL-ST-KDI             0            0.0000   \n",
       "1 2025-08-02  06.11251.2005  IEL-ST-KDI             0            0.0000   \n",
       "2 2025-08-03  06.11251.2005  IEL-ST-KDI             0            0.0000   \n",
       "3 2025-08-04  06.11251.2005  IEL-ST-KDI             0            0.0000   \n",
       "4 2025-08-05  06.11251.2005  IEL-ST-KDI             0            0.0000   \n",
       "\n",
       "   forecast_qty_raw_model  \n",
       "0                  0.0310  \n",
       "1                  0.0486  \n",
       "2                  0.0355  \n",
       "3                  0.0756  \n",
       "4                  0.0690  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 1) Pilih best model berdasar MAPE% terkecil ===\n",
    "eval_target = f\"rounded(thr={ZERO_THR})\"\n",
    "subset = results_df[results_df[\"eval\"] == eval_target]\n",
    "if subset.empty:                             \n",
    "    eval_target = \"raw\"\n",
    "    subset = results_df[results_df[\"eval\"] == eval_target]\n",
    "\n",
    "best_row  = subset.sort_values(\"MAPE%\").iloc[0]\n",
    "best_name = best_row[\"model\"]\n",
    "best_est  = fitted[best_name]\n",
    "print(f\"Best model by MAPE% on {eval_target}: {best_name} | MAPE%={best_row['MAPE%']:.4f}\")\n",
    "\n",
    "# === 2) Siapkan subset site untuk OUTPUT (training tetap dari df) ===\n",
    "df_sites = df if 'FORECAST_SITE_CODES' not in globals() or (FORECAST_SITE_CODES is None) \\\n",
    "              else df[df['site_code'].isin(FORECAST_SITE_CODES)].copy()\n",
    "if df_sites.empty:\n",
    "    raise ValueError(\"FORECAST_SITE_CODES tidak ditemukan di data.\")\n",
    "\n",
    "# === 3) Satu-hari forecast helper ===\n",
    "def one_day_forecast(history_df, fdate):\n",
    "    # Fitur terakhir dari histori\n",
    "    hist = add_calendar_features(history_df)\n",
    "    hist = add_group_lags_rolls(hist, group_cols, target_col='demand_qty',\n",
    "                                lags=(1,7,14,28), roll_windows=(7,14,28))\n",
    "    latest = (hist.sort_values('date')\n",
    "                .groupby(group_cols, as_index=False)\n",
    "                .tail(1)[[*group_cols] + [c for c in hist.columns\n",
    "                                          if c.startswith('lag_') or c.startswith('rollmean_')]])\n",
    "\n",
    "    # Kombinasi (part, site) di tanggal fdate\n",
    "    combos = df_sites[group_cols].drop_duplicates().reset_index(drop=True)\n",
    "    combos['date'] = fdate\n",
    "    combos = add_calendar_features(combos).merge(latest, on=group_cols, how='left')\n",
    "\n",
    "    # Isi NaN untuk fitur lag/rolling\n",
    "    lagroll_cols = [c for c in feature_cols_num if c.startswith('lag_') or c.startswith('rollmean_')]\n",
    "    for c in lagroll_cols:\n",
    "        if c in combos:\n",
    "            combos[c] = combos[c].fillna(0)\n",
    "\n",
    "    # Prediksi → threshold → pembulatan\n",
    "    Xf = pd.concat([combos[feature_cols_cat], combos[feature_cols_num]], axis=1)\n",
    "    raw_model = np.maximum(0, best_est.predict(Xf))              # mentah dari model\n",
    "    raw_thr   = np.where(raw_model < ZERO_THR, 0, raw_model)     # setelah threshold\n",
    "    combos['forecast_qty_raw_model'] = raw_model\n",
    "    combos['forecast_qty_raw']       = raw_thr\n",
    "    combos['forecast_qty']           = round_series(raw_thr, ROUNDING_MODE)\n",
    "    combos['date'] = fdate\n",
    "\n",
    "    return combos[['date','partnumber','site_code',\n",
    "                   'forecast_qty','forecast_qty_raw','forecast_qty_raw_model']]\n",
    "\n",
    "# === 4) Tentukan tanggal mulai & histori sampai H-1 ===\n",
    "max_hist   = df_sites['date'].max()\n",
    "start_date = pd.to_datetime(FORECAST_START_DATE) if FORECAST_START_DATE \\\n",
    "             else (max_hist + pd.Timedelta(days=FORECAST_START_OFFSET_DAYS))\n",
    "\n",
    "history = (df_sites[df_sites['date'] <= start_date - pd.Timedelta(days=1)].copy()\n",
    "           if start_date <= max_hist else df_sites.copy())\n",
    "\n",
    "# Warm-up kalau ada gap sebelum start_date\n",
    "gap = history['date'].max() + pd.Timedelta(days=1)\n",
    "while gap < start_date:\n",
    "    tmp = one_day_forecast(history, gap)\n",
    "    # feed-back menggunakan nilai setelah threshold\n",
    "    history = pd.concat([history,\n",
    "                         tmp.rename(columns={'forecast_qty_raw':'demand_qty'})\n",
    "                           [['date','partnumber','site_code','demand_qty']]],\n",
    "                        ignore_index=True)\n",
    "    gap += pd.Timedelta(days=1)\n",
    "\n",
    "# === 5) Forecast utama untuk horizon ===\n",
    "forecasts = []\n",
    "for d in pd.date_range(start_date, periods=FORECAST_HORIZON, freq='D'):\n",
    "    out = one_day_forecast(history, d)\n",
    "    forecasts.append(out)\n",
    "    history = pd.concat([history,\n",
    "                         out.rename(columns={'forecast_qty_raw':'demand_qty'})\n",
    "                           [['date','partnumber','site_code','demand_qty']]],\n",
    "                        ignore_index=True)\n",
    "\n",
    "forecast_df = (pd.concat(forecasts, ignore_index=True)\n",
    "                 .sort_values(['partnumber','site_code','date'])\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nSample forecast:\")\n",
    "display(forecast_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1b322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df.to_csv(\"forecast_best_by_mape.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample output:\n",
      "        date partnumber site_code  forecast_qty  forecast_qty_raw  \\\n",
      "0 2025-08-01              Kendari             0               0.0   \n",
      "1 2025-08-02              Kendari             0               0.0   \n",
      "2 2025-08-03              Kendari             0               0.0   \n",
      "3 2025-08-04              Kendari             0               0.0   \n",
      "4 2025-08-05              Kendari             0               0.0   \n",
      "\n",
      "   forecast_qty_raw_model  \n",
      "0                0.000000  \n",
      "1                0.016655  \n",
      "2                0.000000  \n",
      "3                0.000592  \n",
      "4                0.000409  \n"
     ]
    }
   ],
   "source": [
    "# 9) FORECAST LOOP (threshold + keep raw_model)\n",
    "# =======================\n",
    "df_sites = df if FORECAST_SITE_CODES is None else df[df['site_code'].isin(FORECAST_SITE_CODES)].copy()\n",
    "if df_sites.empty:\n",
    "    raise ValueError(\"FORECAST_SITE_CODES tidak ditemukan di data.\")\n",
    "\n",
    "def one_day_forecast(history_df, fdate):\n",
    "    hist = add_calendar_features(history_df)\n",
    "    hist = add_group_lags_rolls(hist, group_cols, target_col='demand_qty',\n",
    "                                lags=(1,7,14,28), roll_windows=(7,14,28))\n",
    "    latest = (hist.sort_values('date')\n",
    "                .groupby(group_cols, as_index=False)\n",
    "                .tail(1)[[*group_cols] + [c for c in hist.columns\n",
    "                                          if c.startswith('lag_') or c.startswith('rollmean_')]])\n",
    "\n",
    "    combos = df_sites[group_cols].drop_duplicates().reset_index(drop=True)\n",
    "    combos['date'] = fdate\n",
    "    combos = add_calendar_features(combos).merge(latest, on=group_cols, how='left')\n",
    "\n",
    "    lagroll_cols = [c for c in feature_cols_num if c.startswith('lag_') or c.startswith('rollmean_')]\n",
    "    for c in lagroll_cols:\n",
    "        if c in combos: combos[c] = combos[c].fillna(0)\n",
    "\n",
    "    Xf = pd.concat([combos[feature_cols_cat], combos[feature_cols_num]], axis=1)\n",
    "    raw_model = np.maximum(0, best_est.predict(Xf))              # prediksi mentah (disimpan)\n",
    "    raw_thr   = np.where(raw_model < ZERO_THR, 0, raw_model)      # terapkan ambang nol\n",
    "\n",
    "    combos['forecast_qty_raw_model'] = raw_model                  # simpan mentah model\n",
    "    combos['forecast_qty_raw'] = raw_thr                          # setelah threshold\n",
    "    combos['forecast_qty'] = round_series(raw_thr, ROUNDING_MODE) # hasil operasional\n",
    "    combos['date'] = fdate\n",
    "\n",
    "    return combos[['date','partnumber','site_code',\n",
    "                   'forecast_qty','forecast_qty_raw','forecast_qty_raw_model']]\n",
    "\n",
    "max_hist = df_sites['date'].max()\n",
    "start_date = pd.to_datetime(FORECAST_START_DATE) if FORECAST_START_DATE else (\n",
    "    max_hist + pd.Timedelta(days=FORECAST_START_OFFSET_DAYS)\n",
    ")\n",
    "\n",
    "history = df_sites[df_sites['date'] <= start_date - pd.Timedelta(days=1)].copy() \\\n",
    "           if start_date <= max_hist else df_sites.copy()\n",
    "\n",
    "gap = history['date'].max() + pd.Timedelta(days=1)\n",
    "while gap < start_date:\n",
    "    tmp = one_day_forecast(history, gap)\n",
    "    # feed-back menggunakan nilai setelah threshold \n",
    "    history = pd.concat([history,\n",
    "                         tmp.rename(columns={'forecast_qty_raw':'demand_qty'})\n",
    "                           [['date','partnumber','site_code','demand_qty']]],\n",
    "                        ignore_index=True)\n",
    "    gap += pd.Timedelta(days=1)\n",
    "\n",
    "forecasts = []\n",
    "for d in pd.date_range(start_date, periods=FORECAST_HORIZON, freq='D'):\n",
    "    out = one_day_forecast(history, d)\n",
    "    forecasts.append(out)\n",
    "    history = pd.concat([history,\n",
    "                         out.rename(columns={'forecast_qty_raw':'demand_qty'})\n",
    "                           [['date','partnumber','site_code','demand_qty']]],\n",
    "                        ignore_index=True)\n",
    "\n",
    "forecast_df = (pd.concat(forecasts, ignore_index=True)\n",
    "                 .sort_values(['partnumber','site_code','date'])\n",
    "                 .reset_index(drop=True))\n",
    "\n",
    "print(\"\\nSample output:\")\n",
    "print(forecast_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a120bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs_forecast11\\forecast_next_7d.csv\n",
      "Saved: outputs_forecast11\\forecast_selected_next_7d.csv\n"
     ]
    }
   ],
   "source": [
    "# 10) SAVE\n",
    "# =======================\n",
    "outdir = Path('outputs_forecast11')\n",
    "safe_save_csv(forecast_df, outdir / f'forecast_next_{FORECAST_HORIZON}d.csv')\n",
    "\n",
    "if FORECAST_SITE_CODES is not None:\n",
    "    sel = forecast_df[forecast_df['site_code'].isin(FORECAST_SITE_CODES)].copy()\n",
    "    safe_save_csv(sel, outdir / f'forecast_selected_next_{FORECAST_HORIZON}d.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
